{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Preparing the Workplace","metadata":{}},{"cell_type":"markdown","source":"### Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:43.500655Z","iopub.execute_input":"2023-01-05T18:54:43.500944Z","iopub.status.idle":"2023-01-05T18:54:43.930783Z","shell.execute_reply.started":"2023-01-05T18:54:43.500922Z","shell.execute_reply":"2023-01-05T18:54:43.930062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extra Settings","metadata":{}},{"cell_type":"code","source":"# Setting the default size of visualisations.\nsns.set(rc={'figure.figsize': (9, 6)})\n\n# Ignoring red warnings\npd.options.mode.chained_assignment = None","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:43.933197Z","iopub.execute_input":"2023-01-05T18:54:43.934928Z","iopub.status.idle":"2023-01-05T18:54:43.939945Z","shell.execute_reply.started":"2023-01-05T18:54:43.934903Z","shell.execute_reply":"2023-01-05T18:54:43.939372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions","metadata":{}},{"cell_type":"code","source":"# ========== Here's the main function for the basic data overview.\n\ndef do_basic_overview(data):\n    print()\n    print(12*'=', 'Basic Info', 12*'=')\n    data.info()\n    print('\\n\\n')\n    print(12*'=', 'First Five Rows', 12*'=')\n    display(data.head())\n    print('\\n\\n')\n    print(12*'=', 'Last Five Rows', 12*'=')\n    display(data.tail())\n    print('\\n\\n')\n    print(12*'=', 'Duplicates', 12*'=')\n    print()\n    if data.duplicated().sum() > 0:\n        print(f'Amount of duplicated rows: {data.duplicated().sum()}.')\n        data.drop_duplicates(inplace=True, ignore_index=True)\n        print('Duplicated rows were dropped.')\n    else:\n        print('None.')\n        \n        \n# Creating histograms for all columns with numeric values in search for some obvious anomalies.\ndef numeric_cols_hist(data, width, height):\n        cols = data.select_dtypes(include=('number')).columns.to_list()\n        data[cols].hist(bins=30, figsize=(width, height))\n        plt.show()\n        print('Here, the density of values in each numeric column is shown.')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-05T18:54:43.941504Z","iopub.execute_input":"2023-01-05T18:54:43.941713Z","iopub.status.idle":"2023-01-05T18:54:43.949641Z","shell.execute_reply.started":"2023-01-05T18:54:43.941693Z","shell.execute_reply":"2023-01-05T18:54:43.94881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Makes a dataframe to overview datatypes\n# for each column of the original dataframe\n\ndef make_df_dtype(data):\n    cols, dtype_col, specimens, nunique, null_share = [], [], [], [], []\n    for column in data:\n        cols.append(column)\n        \n        this_dtype = data[column].dtype\n        dtype_col.append(this_dtype)\n        \n        specimen = data.loc[data[column].first_valid_index(), column]\n        specimens.append(specimen)\n        \n        nunique.append(data[column].nunique())\n        \n        null_sum = data[column].isna().sum()\n        null_to_len = null_sum / len(data[column])\n        null_share.append(f'{null_to_len:.2%}')\n        \n    df = pd.DataFrame(list(zip(dtype_col,\n                               specimens,\n                               nunique,\n                              null_share)),\n                      index=cols)    \n    df.columns=['dtype',\n                'specimen',\n                'nunique',\n               'null_share']\n \n    return (df.style.set_properties(**{'text-align': 'left'}))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-05T18:54:43.951461Z","iopub.execute_input":"2023-01-05T18:54:43.951701Z","iopub.status.idle":"2023-01-05T18:54:43.961227Z","shell.execute_reply.started":"2023-01-05T18:54:43.95168Z","shell.execute_reply":"2023-01-05T18:54:43.960558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating share of null values for the column.\ndef print_null_share(column):\n    null_sum = data[column].isna().sum()\n    null_to_len = null_sum / len(data[column])\n    print(f\"'{column}', percentage of null-values: {null_to_len:.2%}.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-01-05T18:54:43.96267Z","iopub.execute_input":"2023-01-05T18:54:43.962985Z","iopub.status.idle":"2023-01-05T18:54:43.970632Z","shell.execute_reply.started":"2023-01-05T18:54:43.962931Z","shell.execute_reply":"2023-01-05T18:54:43.969908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/revealing-insights-from-youtube-video-and-channe/YouTubeDataset_withChannelElapsed.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:43.971753Z","iopub.execute_input":"2023-01-05T18:54:43.972313Z","iopub.status.idle":"2023-01-05T18:54:47.931818Z","shell.execute_reply.started":"2023-01-05T18:54:43.97229Z","shell.execute_reply":"2023-01-05T18:54:47.931091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Overview and Preprocessing ","metadata":{}},{"cell_type":"markdown","source":"This dataset contains YouTube video and channel metadata.\n\nLet us take a first glance on the information we have.","metadata":{}},{"cell_type":"markdown","source":"### First Glance","metadata":{}},{"cell_type":"markdown","source":"NB: `elapsed time` - average time spent watching a video per user.","metadata":{}},{"cell_type":"markdown","source":"|Column name|Description|\n|:----|:----|\n|totalviews/channelelapsedtime|Ratio of total views to channel elapsed time. (Ratio)|\n|channelViewCount|Total number of views for the channel. (Integer)|\n|likes/subscriber|Ratio of likes to subscribers. (Ratio)|\n|views/subscribers|Ratio of views to subscribers. (Ratio)|\n|subscriberCount|Total number of subscribers for the channel. (Integer)|\n|dislikes/views|Ratio of dislikes to views. (Ratio)|\n|comments/subscriber|Ratio of comments to subscribers. (Ratio)|\n|channelCommentCount|Total number of comments for the channel. (Integer)|\n|likes/dislikes|Ratio of likes to dislikes. (Ratio)|\n|comments/views|Ratio of comments to views. (Ratio)|\n|dislikes/subscriber|Ratio of dislikes to subscribers. (Ratio)|\n|totviews/totsubs|Ratio of total views to total subscribers. (Ratio)|\n|views/elapsedtime|Ratio of views to elapsed time. (Ratio)|\n","metadata":{}},{"cell_type":"code","source":"make_df_dtype(data)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:47.934941Z","iopub.execute_input":"2023-01-05T18:54:47.935167Z","iopub.status.idle":"2023-01-05T18:54:48.785292Z","shell.execute_reply.started":"2023-01-05T18:54:47.935145Z","shell.execute_reply":"2023-01-05T18:54:48.784571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-01-05T19:01:32.031129Z","iopub.execute_input":"2023-01-05T19:01:32.031499Z","iopub.status.idle":"2023-01-05T19:01:32.411184Z","shell.execute_reply.started":"2023-01-05T19:01:32.03147Z","shell.execute_reply":"2023-01-05T19:01:32.410593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First insights","metadata":{}},{"cell_type":"markdown","source":"- We have mostly numeric data.\n- In some cases, there are numericish-looking timestamps and categorical values (for instance, video categories: we will decipher them later by borrowing their meaning from [here](https://gist.github.com/dgp/1b24bf2961521bd75d6c)).\n- For some reasons, some ratio columns ('likes/subscriber' etc.) have negative values in it: is `-1` a placeholder for null-values? The column dedicated to ratio of likes to dislikes predominantly consists of `-2`'s. We need to do something about it.\n- Not all the columns are covered in depth in the data description. For instance, we don't know what unit is used in case of 'elapsed_time' (seconds? minutes?).\n\nAs our next step, we will do some housekeeping and go through a deeper data overview.","metadata":{}},{"cell_type":"markdown","source":"### Further Overview and Housekeeping","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:49.153101Z","iopub.execute_input":"2023-01-05T18:54:49.153563Z","iopub.status.idle":"2023-01-05T18:54:49.237426Z","shell.execute_reply.started":"2023-01-05T18:54:49.153531Z","shell.execute_reply":"2023-01-05T18:54:49.236576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, let's do some preparatory work with columns names and data types.","metadata":{}},{"cell_type":"code","source":"# Converting column names to snake_case.\npattern = re.compile(r'(?<!^)(?=[A-Z])')\n\nfor column in data.columns:\n    column_upd = pattern.sub('_', column).lower()\n    data = data.rename(columns={column: column_upd})\n    \ndata = data.rename(columns={\n    'totalviews/channelelapsedtime': 'total_views/channel_elapsed_time',\n                    'channelelapsedtime': 'channel_elapsed_time',\n                    'totvideos/videocount': 'total_videos/video_count',\n                    'elapsedtime': 'elapsed_time',\n                    'totviews/totsubs': 'total_views/total_subscribers',\n                    'views/elapsedtime': 'views/elapsed_time'})\n\n\n# Let's drop the index column.\ndata = data.drop(['index'], axis=1)\n\n\n# Let's identify our dates as dates.\ndata['video_published'] = pd.to_datetime(data['video_published'])\n\n\n# For now, let us cast the ids of video categories as strings they practically are.\ndata['video_category_id'] = data['video_category_id'].astype('str')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:49.240532Z","iopub.execute_input":"2023-01-05T18:54:49.24081Z","iopub.status.idle":"2023-01-05T18:54:50.556499Z","shell.execute_reply.started":"2023-01-05T18:54:49.240787Z","shell.execute_reply":"2023-01-05T18:54:50.555637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make our futher visualisations more clear, let us decipher video categories.","metadata":{}},{"cell_type":"code","source":"data['video_category'] = np.nan\n\nfor item in [['2', 'Autos & Vehicles'], ['1', 'Film & Animation'],\n             ['10', 'Music'], ['15', 'Pets & Animals'],\n             ['17', 'Sports'], ['18', 'Short Movies'],\n             ['19', 'Travel & Events'], ['20', 'Gaming'],\n             ['21', 'Videoblogging'], ['22', 'People & Blogs'],\n             ['23', 'Comedy'], ['24', 'Entertainment'],\n             ['25', 'News & Politics'], ['26', 'Howto & Style'],\n             ['27', 'Education'], ['28', 'Science & Technology'],\n             ['29', 'Nonprofits & Activism'], ['30', 'Movies'],\n             ['31', 'Anime/Animation'], ['32', 'Action/Adventure'],\n             ['33', 'Classics'], ['34', 'Comedy'], ['35', 'Documentary'],\n             ['36', 'Drama'], ['37', 'Family'], ['38', 'Foreign'],\n             ['39', 'Horror'], ['40', 'Sci-Fi/Fantasy'], ['41', 'Thriller'],\n             ['42', 'Shorts'], ['43', 'Shows'], ['44', 'Trailers']]:\n    \n    (data\n     .loc[data['video_category_id'] == item[0],\n          'video_category']) = item[1]\n\nprint_null_share('video_category')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:50.557763Z","iopub.execute_input":"2023-01-05T18:54:50.558001Z","iopub.status.idle":"2023-01-05T18:54:52.029851Z","shell.execute_reply.started":"2023-01-05T18:54:50.557979Z","shell.execute_reply":"2023-01-05T18:54:52.029002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_df_dtype(data)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:52.032196Z","iopub.execute_input":"2023-01-05T18:54:52.032473Z","iopub.status.idle":"2023-01-05T18:54:52.798163Z","shell.execute_reply.started":"2023-01-05T18:54:52.032451Z","shell.execute_reply":"2023-01-05T18:54:52.797377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_basic_overview(data)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:52.79923Z","iopub.execute_input":"2023-01-05T18:54:52.799517Z","iopub.status.idle":"2023-01-05T18:54:56.122609Z","shell.execute_reply.started":"2023-01-05T18:54:52.799494Z","shell.execute_reply":"2023-01-05T18:54:56.121693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, we had some explicitly duplicated rows.\n<br>About 3.3% of our original data, to put it relatively (this sounds less frightening than 19&nbsp;186 rows).\n\nWe will be on our toes to catch implicit ones, too, if needed.","metadata":{}},{"cell_type":"markdown","source":"### Density of Numeric Values","metadata":{}},{"cell_type":"code","source":"numeric_cols_hist(data, width=25, height=19)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:56.125277Z","iopub.execute_input":"2023-01-05T18:54:56.125558Z","iopub.status.idle":"2023-01-05T18:54:59.905184Z","shell.execute_reply.started":"2023-01-05T18:54:56.125534Z","shell.execute_reply":"2023-01-05T18:54:59.904356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we can see, most of our distributions have a very strong right skewness.\n<br>This means, there is a long 'tail' to the right. Judging by the ticks on the x-axis, sometimes it reaches quite impressive values, but it can't be seen at the current scale.\n<br>At the same time, in most cases, there is a peak on the left, somewhere closer to the zero point.\n- We still need to do something about mysterious negative ratios.","metadata":{}},{"cell_type":"markdown","source":"### Dealing with Negative Values (where they don't belong)","metadata":{}},{"cell_type":"markdown","source":"It is impossible for a ratio to be negative.\n\nA number of something can't be less than zero as well.\n\nWe can asume that some negative value can stand for the gap in the original data being, in fact, a placeholder.<br>However, in this case, we should see some pattern and uniformity of usage. For instance, only `-1` shall be used.\n\nIn other cases, we need to do something about it.\n<br><br>\nLet us explore the columns 'below zero'.<br>After this, we will wipe all the negative values away.<br>It will be quite easy to fill the null values once again or drop them completely, if needed.","metadata":{}},{"cell_type":"code","source":"# Let's keep columns with negative values in a list.\ncolumns_below_zero = []\n\n# We will go through the columns with numeric values of our dataset.\nfor column_name in data.select_dtypes(include='number').columns.to_list():\n    if data[column_name].min() < 0:\n        columns_below_zero.append(f'{column_name}')\n        print(f\"'{column_name}'\")\n        \n        # We will print unique negative values.\n        # At the same time, we need to set a limit to keep it quick.\n        print(\"Unique values 'below zero':\")\n        i = 0\n        for elem in data.loc[data[column_name] < 0][column_name].unique():\n            print(f'{elem}')\n            i += 1\n            # If more than 5 values is already printed, it stops.\n            if i > 4:\n                print('- and others.')\n                break\n                \n        print(f\"Minimum value: {data[column_name].min()}\")\n        \n        # Now, we will wipe the negative values away.\n        print_null_share(column_name)\n        print('--> Now, we are erasing negative values.')\n        data.loc[data[column_name] < 0, column_name] = np.nan\n        print_null_share(column_name)\n        print()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:54:59.906635Z","iopub.execute_input":"2023-01-05T18:54:59.906937Z","iopub.status.idle":"2023-01-05T18:55:00.266204Z","shell.execute_reply.started":"2023-01-05T18:54:59.906907Z","shell.execute_reply":"2023-01-05T18:55:00.265285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_df_dtype(data[columns_below_zero])","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:00.267513Z","iopub.execute_input":"2023-01-05T18:55:00.26785Z","iopub.status.idle":"2023-01-05T18:55:00.538186Z","shell.execute_reply.started":"2023-01-05T18:55:00.267819Z","shell.execute_reply":"2023-01-05T18:55:00.537617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Having in mind the uniformity of usage of `-1` in several columns, we could have thought about being a substitute for null-values.\n\nHowever, in other columns the situation is more nuanced, and there is a bigger variety of possible negative values that can't be explained by conventions and/or some natural causes.\n\n**We will fill the gaps with median for this or that video category**<br>\nIn most cases, most of the values are positive: negative values are making up way less than 5-6% of this or that particular column. Whatever we do, hopefully, we will not affect the majority of rows and overall pattern.<br>To make the values less artificial and not to erase rows, we will fill the null-values with median value calculated for each video category.\n\n**We will drop 'likes/dislikes' column**<br>\nThere is only one exception, and it is 'likes/dislikes' column: it is almost completely 'below zero'! There is no need to keep it in our dataset.","metadata":{}},{"cell_type":"code","source":"# Filling the gaps.\nfor column_name in columns_below_zero:\n    data[column_name] = data[column_name].fillna(data\n                                               .groupby('video_category')\n                                               [column_name].transform(\"median\"))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:00.538969Z","iopub.execute_input":"2023-01-05T18:55:00.539346Z","iopub.status.idle":"2023-01-05T18:55:01.435716Z","shell.execute_reply.started":"2023-01-05T18:55:00.539311Z","shell.execute_reply":"2023-01-05T18:55:01.434862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the column.\ndata = data.drop(['likes/dislikes'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:01.436701Z","iopub.execute_input":"2023-01-05T18:55:01.436941Z","iopub.status.idle":"2023-01-05T18:55:01.485236Z","shell.execute_reply.started":"2023-01-05T18:55:01.43692Z","shell.execute_reply":"2023-01-05T18:55:01.484401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_df_dtype(data)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:01.486238Z","iopub.execute_input":"2023-01-05T18:55:01.486479Z","iopub.status.idle":"2023-01-05T18:55:02.269516Z","shell.execute_reply.started":"2023-01-05T18:55:01.486457Z","shell.execute_reply":"2023-01-05T18:55:02.268885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.270297Z","iopub.execute_input":"2023-01-05T18:55:02.270976Z","iopub.status.idle":"2023-01-05T18:55:02.366616Z","shell.execute_reply.started":"2023-01-05T18:55:02.270952Z","shell.execute_reply":"2023-01-05T18:55:02.365816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Organising the Features","metadata":{}},{"cell_type":"markdown","source":"Before we dive into our futher exploration, let's bring some order into our list of our numeric non-categorical features.\n\nThey can be naturally divided into three categories:\n- dealing with videos (even though 'video_category_id' and 'video_published_year' are categorical, we will classify list it here as well)\n- dealing with channels\n- dealing with ratios\n\nFirstly, we will divide the list of columns into three categories based on their names.\n\nWe will be able to make some manual edits after that (if needed).","metadata":{}},{"cell_type":"code","source":"video_details = []\nchannel_details = []\nratios = []\nfor col in data.select_dtypes(include='number').columns.to_list():\n    if \"/\" not in col:\n        if 'video' in col:\n            video_details.append(col)\n        if 'channel' in col:\n            channel_details.append(col)\n    elif '/' in col:\n        ratios.append(col)\n    else:\n        print(f'!!! Was not classified: {col}.\\n')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.367773Z","iopub.execute_input":"2023-01-05T18:55:02.368207Z","iopub.status.idle":"2023-01-05T18:55:02.38821Z","shell.execute_reply.started":"2023-01-05T18:55:02.368184Z","shell.execute_reply":"2023-01-05T18:55:02.387378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's keep our orginised features in a special `data_dict` where they can be easily accessible.","metadata":{}},{"cell_type":"code","source":"data_dict = {\n    'video_details': video_details,\n    'channel_details': channel_details,\n    'ratios': ratios\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.389465Z","iopub.execute_input":"2023-01-05T18:55:02.389855Z","iopub.status.idle":"2023-01-05T18:55:02.393066Z","shell.execute_reply.started":"2023-01-05T18:55:02.389832Z","shell.execute_reply":"2023-01-05T18:55:02.392486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the result.","metadata":{}},{"cell_type":"code","source":"data_dict['video_details']","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.393881Z","iopub.execute_input":"2023-01-05T18:55:02.394726Z","iopub.status.idle":"2023-01-05T18:55:02.406104Z","shell.execute_reply.started":"2023-01-05T18:55:02.394694Z","shell.execute_reply":"2023-01-05T18:55:02.40538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dict['channel_details']","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.407066Z","iopub.execute_input":"2023-01-05T18:55:02.407567Z","iopub.status.idle":"2023-01-05T18:55:02.415082Z","shell.execute_reply.started":"2023-01-05T18:55:02.407543Z","shell.execute_reply":"2023-01-05T18:55:02.414207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dict['ratios']","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.416997Z","iopub.execute_input":"2023-01-05T18:55:02.417279Z","iopub.status.idle":"2023-01-05T18:55:02.422965Z","shell.execute_reply.started":"2023-01-05T18:55:02.41725Z","shell.execute_reply":"2023-01-05T18:55:02.422047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's Built Some Boxplots to Take a Look at the Numeric Values","metadata":{}},{"cell_type":"code","source":"for item in data_dict['video_details']:\n    sns.boxplot(x=data[item])\n    plt.title(f\"Information about videos:\\n'{item}'\", fontsize=25)\n    plt.show()\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:02.42391Z","iopub.execute_input":"2023-01-05T18:55:02.424153Z","iopub.status.idle":"2023-01-05T18:55:03.745845Z","shell.execute_reply.started":"2023-01-05T18:55:02.424131Z","shell.execute_reply":"2023-01-05T18:55:03.744852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in data_dict['channel_details']:\n    sns.boxplot(x=data[item])\n    plt.title(f\"Information about channels:\\n'{item}'\", fontsize=25)\n    plt.show()\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:03.747165Z","iopub.execute_input":"2023-01-05T18:55:03.7481Z","iopub.status.idle":"2023-01-05T18:55:04.478074Z","shell.execute_reply.started":"2023-01-05T18:55:03.748054Z","shell.execute_reply":"2023-01-05T18:55:04.477164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As our histograms have already shown us, we have a very strong right skewness.\n\nThe *box* (the lowest and highest data points in the data set excluding any statistically defined outliers) is indistinguishable in most of the cases, leaving us with plenty of outliers (diamond-shaped black points; sometimes they are merging together).","metadata":{}},{"cell_type":"code","source":"# we can cast the ids of video categories back to integers and add it to the list of categories\ndata.video_category_id = data.video_category_id.astype('int')\n\ndata_dict['video_details'].append('video_category_id')\ndata_dict['video_details']","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:04.482899Z","iopub.execute_input":"2023-01-05T18:55:04.483552Z","iopub.status.idle":"2023-01-05T18:55:04.559139Z","shell.execute_reply.started":"2023-01-05T18:55:04.483524Z","shell.execute_reply":"2023-01-05T18:55:04.558338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Time range","metadata":{}},{"cell_type":"code","source":"data['video_published'].hist()\nplt.title(\"'video_published' values\", fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:04.560193Z","iopub.execute_input":"2023-01-05T18:55:04.560444Z","iopub.status.idle":"2023-01-05T18:55:04.823779Z","shell.execute_reply.started":"2023-01-05T18:55:04.560421Z","shell.execute_reply":"2023-01-05T18:55:04.82312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's add a new column for years: it can be useful for dynamic analysis.","metadata":{}},{"cell_type":"code","source":"data['video_published_year'] = data['video_published'].dt.year\ndata[['video_published_year', 'video_published']].head()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:04.824681Z","iopub.execute_input":"2023-01-05T18:55:04.825139Z","iopub.status.idle":"2023-01-05T18:55:04.871178Z","shell.execute_reply.started":"2023-01-05T18:55:04.825113Z","shell.execute_reply":"2023-01-05T18:55:04.870341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, our histogram offered us a shortened version of list of years.\n\nLet's group our data by years.","metadata":{}},{"cell_type":"code","source":"(\n    data.groupby('video_published_year')\n    .agg(total_videos_published=('video_id', 'nunique'),\n         total_channels_with_new_videos=('channel_id', 'nunique'))\n).style.background_gradient(cmap='Blues_r')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:04.872181Z","iopub.execute_input":"2023-01-05T18:55:04.872448Z","iopub.status.idle":"2023-01-05T18:55:05.198094Z","shell.execute_reply.started":"2023-01-05T18:55:04.872425Z","shell.execute_reply":"2023-01-05T18:55:05.19732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Correlations","metadata":{}},{"cell_type":"code","source":"correlations = round(data.corr(), 2)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:05.199186Z","iopub.execute_input":"2023-01-05T18:55:05.199429Z","iopub.status.idle":"2023-01-05T18:55:05.753143Z","shell.execute_reply.started":"2023-01-05T18:55:05.199407Z","shell.execute_reply":"2023-01-05T18:55:05.752318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Significant negative linear correlation:')\nfor column_name in correlations.columns.to_list():\n    inds = (correlations\n            .loc[correlations[column_name] < -0.5]\n            .index.to_list())       \n    for elem in inds:\n        print(f\"- `{elem}` - `{column_name}`\")","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:05.754109Z","iopub.execute_input":"2023-01-05T18:55:05.754364Z","iopub.status.idle":"2023-01-05T18:55:05.766422Z","shell.execute_reply.started":"2023-01-05T18:55:05.754323Z","shell.execute_reply":"2023-01-05T18:55:05.765483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Very strong positive linear correlation:')\nfor column_name in correlations.columns.to_list():\n    inds = (correlations.loc[correlations[column_name] >= 0.9].index.to_list())\n    for elem in inds:\n        if elem != column_name:\n            print(f\"- `{elem}` - `{column_name}`\")","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:05.767827Z","iopub.execute_input":"2023-01-05T18:55:05.768122Z","iopub.status.idle":"2023-01-05T18:55:05.782043Z","shell.execute_reply.started":"2023-01-05T18:55:05.768093Z","shell.execute_reply":"2023-01-05T18:55:05.781356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Strong positive linear correlation:')\nfor column_name in correlations.columns.to_list():\n    inds = (correlations\n            .loc[(correlations[column_name] <= 0.9) & (correlations[column_name] >= 0.7)]\n            .index.to_list())       \n    for elem in inds:\n        print(f\"- `{elem}` - `{column_name}`\")","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:05.782996Z","iopub.execute_input":"2023-01-05T18:55:05.783801Z","iopub.status.idle":"2023-01-05T18:55:05.803739Z","shell.execute_reply.started":"2023-01-05T18:55:05.783777Z","shell.execute_reply":"2023-01-05T18:55:05.802964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.corr(), cmap='viridis')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:05.804977Z","iopub.execute_input":"2023-01-05T18:55:05.805235Z","iopub.status.idle":"2023-01-05T18:55:06.878067Z","shell.execute_reply.started":"2023-01-05T18:55:05.805212Z","shell.execute_reply":"2023-01-05T18:55:06.877312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Negative correlations**<br>\nNegative linear correlation means the growth of something goes hand-by-hand with something else's decrease.<br>In case of our data, those correlations are time-related and thus are natural.\n<br><br>\n\nAs we were able to see, there are some significant positive linear correlations.\n\n**Very strong positive correlation**\n- `channel_view_count` - `total_views/channel_elapsed_time`\n- `views/elapsed_time` - `video_view_count`\n<br><br>\n\n**Strong positive linear correlation**\n- `subscriber_count` - `total_views/channel_elapsed_time`\n- `subscriber_count` - `channel_view_count`\n- `video_like_count` - `video_view_count`\n- `video_dislike_count` - `video_view_count`\n- `video_comment_count` - `video_like_count`\n- `views/elapsed_time` - `video_dislike_count`\n","metadata":{}},{"cell_type":"markdown","source":"### Organising the Categories","metadata":{}},{"cell_type":"code","source":"categories = (data\n              .select_dtypes(include='object')\n              .columns.to_list())\ncategories.append('video_published_year')\n\nprint('We have the following categorical columns:')\nfor column_name in categories:\n    nunique = data[column_name].nunique()\n    print(f'- {column_name}: {nunique} unique values')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:06.879462Z","iopub.execute_input":"2023-01-05T18:55:06.87977Z","iopub.status.idle":"2023-01-05T18:55:07.196652Z","shell.execute_reply.started":"2023-01-05T18:55:06.87974Z","shell.execute_reply":"2023-01-05T18:55:07.195804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We have a decent amount of video and channel ids: about half a million and a bit less/more in each case. It can be a blessing and a curse, if not handled wisely.\n- 18 thematic categories for videos is not that much. Yet, still, this list is quite long to be used for some complex visualisations without some adjustments.\n- A year of publishing can be used to show/take into consideration temporal dynamics of any kind: it can be crucial since we are dealing with more than a decade.","metadata":{}},{"cell_type":"markdown","source":"Let's add the list of our categories into data_dict.","metadata":{}},{"cell_type":"code","source":"data_dict['categories'] = categories\ndata_dict['categories']","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:07.197993Z","iopub.execute_input":"2023-01-05T18:55:07.198637Z","iopub.status.idle":"2023-01-05T18:55:07.205211Z","shell.execute_reply.started":"2023-01-05T18:55:07.198605Z","shell.execute_reply":"2023-01-05T18:55:07.204183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## What's Next? (grouping the data to demonstrate interrelations of categories)","metadata":{}},{"cell_type":"markdown","source":"There are chances that we already have the design of our research (more or less) at the moment we open the csv-file.\n<br>Maybe, we are relying on the first findings to tailor the possibilities of the particular dataset to our possible needs and, as a result, to formulate our questions.\n<br><br>In both cases, we have two options.<br><br>\nFirstly, we can explore our dataset in depth as a whole unit.\n<br>Almost half a million channels, more than a decade of observations: all this can be insightful.\n\nBut, secondly, there's another option.<br>We can extract a more limited sample, say:\n- the most active channels\n- the most recent videos\n- one particular thematic category (or categories)\n- etc.\n\nTo ground our decisions better, let's take a look at the interrelations of the categorical data we're having: channel ids, video ids, years when videos were published and thematic categories of videos. ","metadata":{}},{"cell_type":"markdown","source":"### Unique Video Ids per Channel","metadata":{}},{"cell_type":"code","source":"# Grouping the data.\nchannels_and_videos = data.groupby('channel_id')['video_id'].nunique()\n\n# Let's make a horisontal barplot out of this!\n(channels_and_videos\n .sort_values(ascending=False)\n .head(15)\n.sort_values(ascending=True)\n.plot(kind='barh', label=''))\n\n# A few extra lines\nmedian_video_per_channel = channels_and_videos.median().astype('int')\nvideo_per_channel_95 = channels_and_videos.quantile(.95).astype('int')\nvideo_per_channel_99 = channels_and_videos.quantile(.99).astype('int')\n\nplt.axvline(x=median_video_per_channel, color='#e1a846', linestyle='dashdot',\n            label=f'{median_video_per_channel}: median amount of videos per channel')\nplt.axvline(x=video_per_channel_95, color='#2eac8b', linestyle='dashdot',\n            label=f'{video_per_channel_95} videos per channel: 95%')\nplt.axvline(x=video_per_channel_99, color='#d496ca', linestyle='dashdot',\n            label=f'{video_per_channel_99} videos per channel: 99%')\n\nplt.legend()\n\nplt.title('15 most active channels\\n(within our dataset)', fontsize=25)\n\nplt.ylabel('channel id')\nplt.xlabel('videos per channel')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:56:48.747966Z","iopub.execute_input":"2023-01-05T18:56:48.748263Z","iopub.status.idle":"2023-01-05T18:56:49.806958Z","shell.execute_reply.started":"2023-01-05T18:56:48.74824Z","shell.execute_reply":"2023-01-05T18:56:49.806114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Channels and videos**\n- There are a few leaders having more than a hundred videos.\n- 99% of our channels show less commitment: they have no more than 5 videos per channel.\n- This means, having more than **five** video uploaded is a **1%** minority affair.\n- Moreover, about half of the channels settle for 2 videos or fewer than that.","metadata":{}},{"cell_type":"markdown","source":"### Unique Video Ids per Thematic Category","metadata":{}},{"cell_type":"code","source":"videos_and_categories = (data\n                         .groupby('video_category')\n                         .agg(unique_video_ids=('video_id', 'nunique'))\n                         .sort_values(ascending=False, by='unique_video_ids'))\n\n(videos_and_categories\n .sort_values(ascending=True, by='unique_video_ids')\n .plot(kind='barh', legend=False))\n\nplt.title('Thematic video categories\\n',\n          fontsize=25)\nplt.ylabel('')\nplt.xlabel('unique video ids')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:08.336352Z","iopub.execute_input":"2023-01-05T18:55:08.336708Z","iopub.status.idle":"2023-01-05T18:55:08.918888Z","shell.execute_reply.started":"2023-01-05T18:55:08.336677Z","shell.execute_reply":"2023-01-05T18:55:08.917992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total amount of unique video ids.\nunique_video_ids = data.video_id.nunique()\n# Calculating share for each category.\nvideos_and_categories['%_of_all_video_ids'] = (round(videos_and_categories['unique_video_ids'] /\n                                                    unique_video_ids,\n                                                    4) * 100).astype('str')\n\nvideos_and_categories.sort_values(by='unique_video_ids', ascending=False).style.background_gradient()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:08.920419Z","iopub.execute_input":"2023-01-05T18:55:08.920787Z","iopub.status.idle":"2023-01-05T18:55:09.04201Z","shell.execute_reply.started":"2023-01-05T18:55:08.920756Z","shell.execute_reply":"2023-01-05T18:55:09.041048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Unique video ids and thematic categories**\n\n- The dominant category within our dataset is `Music` (almost 20% of unique video ids).\n- Music videos are ahead by a wide margin from closest competitors: `Entertainment`, `Gaming`, `People and Blogs` and `Sports` (13-10%).\n- `Nonprofits & Activism`, `Shows`, `Trailers` and `Movies` are the most underrepresented categories. Each of them comprises less than 0.7%. The latter two are almost non-existent within the dataset (a few hundredths of a percent per each).","metadata":{}},{"cell_type":"markdown","source":"### Age of the Channel","metadata":{}},{"cell_type":"markdown","source":"Now, let's dive into the time flow.","metadata":{}},{"cell_type":"code","source":"# For each channel, we will find out what year first and last videos were published.\nchannels_and_years = (\n    data.groupby('channel_id')\n    .agg(first_year=('video_published_year', 'min'),\n         last_year=('video_published_year', 'max'))\n)\nchannels_and_years","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:09.04461Z","iopub.execute_input":"2023-01-05T18:55:09.044854Z","iopub.status.idle":"2023-01-05T18:55:09.77332Z","shell.execute_reply.started":"2023-01-05T18:55:09.044833Z","shell.execute_reply":"2023-01-05T18:55:09.77242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(channels_and_years.sort_values(by='first_year').T)\n\nplt.title('First and last years per channel\\n(channels are sorted by the first year)\\n', fontsize=25)\n# Switching off the X-ticks to avoid the mess.\nplt.xticks([], [])\nplt.xlabel('channels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:09.774642Z","iopub.execute_input":"2023-01-05T18:55:09.774875Z","iopub.status.idle":"2023-01-05T18:55:23.10756Z","shell.execute_reply.started":"2023-01-05T18:55:09.774853Z","shell.execute_reply":"2023-01-05T18:55:23.106956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(channels_and_years.sort_values(by='last_year').T)\n\nplt.title('First and last years per channel\\n(channels are sorted by the last year)\\n', fontsize=25)\n# Switching off the X-ticks.\nplt.xticks([], [])\nplt.xlabel('channels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:23.108493Z","iopub.execute_input":"2023-01-05T18:55:23.108829Z","iopub.status.idle":"2023-01-05T18:55:36.291519Z","shell.execute_reply.started":"2023-01-05T18:55:23.108807Z","shell.execute_reply":"2023-01-05T18:55:36.290938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Channels and years**\n- For each channel, we have found out what year first and last videos were published.\n<br>With 449&nbsp;980 unique channel ids, the resulting table seems to be impossible to fit to the screen.\n- Thanks to our crazy idea to create a heatmap, even a tiny visualisation may suffice to see the pattern.\n<br>For the majority of channels, the first year was also the last.<br>At the same time, we do have some 'long-livers', and the 'lighter' part is quite 'stripey'.","metadata":{}},{"cell_type":"markdown","source":"### Years and Video Categories","metadata":{}},{"cell_type":"code","source":"(\n    data.groupby('video_category')\n    .agg(earliest_published=('video_published_year', 'min'),\n         latestest_published=('video_published_year', 'max'))\n).style.background_gradient(cmap='Blues_r')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:36.292422Z","iopub.execute_input":"2023-01-05T18:55:36.292762Z","iopub.status.idle":"2023-01-05T18:55:36.359266Z","shell.execute_reply.started":"2023-01-05T18:55:36.29274Z","shell.execute_reply":"2023-01-05T18:55:36.358691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_videos_and_years = (data\n          .groupby(['video_category', 'video_published_year'], as_index=False)\n          .agg(number_of_videos=('video_id', 'nunique'))\n          .sort_values(by='number_of_videos', ascending=False))\n\nsns.lineplot(data=data_videos_and_years,\n             x=\"video_published_year\", y='number_of_videos',\n             hue=\"video_category\")\nplt.title('Videos of each category\\npublished each year\\n', fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:36.360162Z","iopub.execute_input":"2023-01-05T18:55:36.360508Z","iopub.status.idle":"2023-01-05T18:55:36.94713Z","shell.execute_reply.started":"2023-01-05T18:55:36.360486Z","shell.execute_reply":"2023-01-05T18:55:36.946393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do you know what's horrible about the visualisation above?<br>18 categories in use are creating some fancy-looking rainbow that is more of an abstract painting, not a useful data visualisation.\n\n\nUnfortunately, we can't just pick up a special palette: having more than five or seven categories is tricky not only in terms of colour choices but also for a human eye to perceive.\n\n\nThere are, however, different ways to solve this problem.\n\nFor instance, we can recreate our lineplot by using only the most active categories, say, five of them. We have already seen overall dynamics, so there's no need to focus on the rest.","metadata":{}},{"cell_type":"code","source":"# We are reusing data grouping 'videos_and_categories' created previously:\n# extracting top 5 video categories from it.\nmost_active_categories = videos_and_categories.head().index.to_list()\n\nsns.lineplot(data=data_videos_and_years.query('video_category in @most_active_categories'),\n             x=\"video_published_year\", y='number_of_videos',\n             hue=\"video_category\",\n             # Now, we are using a more inclusive palette.\n             palette='colorblind')\nplt.title('Videos of each category\\npublished each year\\n', fontsize=25)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T18:55:36.948161Z","iopub.execute_input":"2023-01-05T18:55:36.949567Z","iopub.status.idle":"2023-01-05T18:55:37.181514Z","shell.execute_reply.started":"2023-01-05T18:55:36.949534Z","shell.execute_reply":"2023-01-05T18:55:37.180844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's better.","metadata":{}},{"cell_type":"markdown","source":"_____________\n\n<br><br>\nI hope this notebook was somehow helpful to you. Any recommendations, bits of advice and edits are more than welcome (showing gratitude in the form of upvoting would bring me joy, too).","metadata":{}}]}